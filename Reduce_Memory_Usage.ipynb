{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPIRP14tK2/ySWIc2qD1402",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hojuna/Black-box_Optimization_dacon/blob/main/Reduce_Memory_Usage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reduce Memory Usage\n",
        "\n",
        "데이터를 경량화 시키고 저번에 메모리 부족으로 돌리지 못한 모델 돌려 보자\n",
        "\n",
        "돌려보니 뭐 다른게 없다. ㅋ 모르겠네 오히려 과대적합 증상을 보임"
      ],
      "metadata": {
        "id": "20yLFRwSgz36"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ryle_3qX2wW",
        "outputId": "bea37540-2a23-4831-8d70-5307023b7c90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJBOLWrp6877"
      },
      "outputs": [],
      "source": [
        "# Reduce Memory Usage\n",
        "# reference : https://www.kaggle.com/code/arjanso/reducing-dataframe-memory-size-by-65 @ARJANGROEN\n",
        "\n",
        "def reduce_memory_usage(df):\n",
        "\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype.name\n",
        "        if ((col_type != 'datetime64[ns]') & (col_type != 'category')):\n",
        "            if (col_type != 'object'):\n",
        "                c_min = df[col].min()\n",
        "                c_max = df[col].max()\n",
        "\n",
        "                if str(col_type)[:3] == 'int':\n",
        "                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                        df[col] = df[col].astype(np.int8)\n",
        "                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                        df[col] = df[col].astype(np.int16)\n",
        "                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                        df[col] = df[col].astype(np.int32)\n",
        "                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                        df[col] = df[col].astype(np.int64)\n",
        "\n",
        "                else:\n",
        "                    if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                        df[col] = df[col].astype(np.float16)\n",
        "                    elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                        df[col] = df[col].astype(np.float32)\n",
        "                    else:\n",
        "                        pass\n",
        "            else:\n",
        "                df[col] = df[col].astype('category')\n",
        "    mem_usg = df.memory_usage().sum() / 1024**2\n",
        "    print(\"Memory usage became: \",mem_usg,\" MB\")\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import os\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV,cross_val_score\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "\n",
        "# Load the data\n",
        "train_df_org = pd.read_csv('/content/drive/MyDrive/dacon/2024_8_data/train.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/dacon/2024_8_data/test.csv')"
      ],
      "metadata": {
        "id": "L12gEbzVYA7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_org_reduced = reduce_memory_usage(train_df_org)\n",
        "test_df_reduced = reduce_memory_usage(test_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOqDJjiThbXO",
        "outputId": "3836d030-e2fd-4078-9f1f-0e5f28c6291a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory usage of dataframe is 3.98 MB\n",
            "Memory usage became:  2.38531494140625  MB\n",
            "Memory usage of dataframe is 0.46 MB\n",
            "Memory usage became:  0.27829742431640625  MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XiLhS8tuofh0"
      },
      "outputs": [],
      "source": [
        "# df_shuffled= train_df_org\n",
        "df_shuffled= train_df_org_reduced\n",
        "\n",
        "# 균등하게 나누기 위해 임의로 데이터를 8:2로 분할\n",
        "split_index = int(len(df_shuffled) * 0.8)\n",
        "train_df, valiation_df = df_shuffled[:split_index], df_shuffled[split_index:]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def val_score(model, valiation_df):\n",
        "  id_y=pd.DataFrame()\n",
        "\n",
        "  top_5_percent_valiation_df = valiation_df.sort_values(by='y').reset_index(drop=True)[-int(0.05 * len(valiation_df)):]\n",
        "  #id만 분리 valiation_df, y값 제거\n",
        "  X = valiation_df.iloc[:, 1:-1]\n",
        "  id_y['ID']=valiation_df.iloc[:,0]\n",
        "\n",
        "  #valiation_df y값 예측\n",
        "  y_pred=model.predict(X)\n",
        "  id_y['y_pred']=y_pred\n",
        "\n",
        "  # print(id_x.head)\n",
        "  # #id 복원\n",
        "\n",
        "  #상위 10% valiation_df 구하기\n",
        "  top_10_percent_pred_valiation=id_y.sort_values(by='y_pred').reset_index(drop=True)[-int(0.10 * len(id_y)):]\n",
        "\n",
        "  # ID 값에서 공백 제거\n",
        "  top_5_percent_valiation_df['ID'] = top_5_percent_valiation_df['ID'].str.strip()\n",
        "  top_10_percent_pred_valiation['ID'] = top_10_percent_pred_valiation['ID'].str.strip()\n",
        "\n",
        "  #top_5_percent_valiation_df 중  상위 10%에 포함되는 비율을 구해서 반환\n",
        "  return top_5_percent_valiation_df['ID'].isin(top_10_percent_pred_valiation['ID']).sum()/len(top_5_percent_valiation_df)"
      ],
      "metadata": {
        "id": "YHSDcCsm3O4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X = train_df.iloc[:, 1:-1]  # Features\n",
        "y = train_df['y']  # Target"
      ],
      "metadata": {
        "id": "ISs65-lwopKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.kernel_ridge import KernelRidge\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import uniform\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "# 데이터 샘플링\n",
        "X_sample, y_sample = shuffle(X, y, random_state=42)  # 데이터 샘플링\n",
        "X_sample = X_sample[:10000]  #10000개의 샘플 사용\n",
        "y_sample = y_sample[:10000]\n",
        "\n",
        "# KernelRidge 모델 초기화\n",
        "model = KernelRidge()\n",
        "\n",
        "# 하이퍼파라미터 범위 설정 (더 좁은 범위)\n",
        "# param_distributions = {\n",
        "#     'alpha': uniform(1e-2, 1e1),  # Regularization strength (범위 축소)\n",
        "#     'kernel': ['linear', 'rbf'],  # Kernel types (범위 축소)\n",
        "#     'gamma': uniform(1e-2, 1e-1),  # Kernel coefficient (범위 축소)\n",
        "#     'degree': [2, 3],  # Degree of the polynomial kernel (적당한 값)\n",
        "#     'coef0': uniform(0, 1)  # Independent term (범위 축소)\n",
        "# }\n",
        "param_distributions = {\n",
        "    'alpha': uniform(1e-4, 1e2),  # Regularization strength: 범위를 넓혀 작은 값부터 큰 값까지 탐색\n",
        "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],  # Kernel types: 다양한 커널 옵션 추가\n",
        "    'gamma': uniform(1e-4, 1e1),  # Kernel coefficient: 범위를 넓혀 작은 값부터 큰 값까지 탐색\n",
        "    'degree': [2,3,4,5, 6],  # Degree of the polynomial kernel: 다양한 다항식 차수 탐색\n",
        "    'coef0': uniform(-1, 2)  # Independent term: 음수 값도 포함하여 범위 확장\n",
        "}\n",
        "\n",
        "\n",
        "# RandomizedSearchCV 설정\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=model,\n",
        "    param_distributions=param_distributions,\n",
        "    n_iter=30,  # 시도할 하이퍼파라미터 조합의 수\n",
        "    cv=3,  # 3-fold cross-validation\n",
        "    scoring='neg_mean_squared_error',  # 평가 척도\n",
        "    random_state=42,  # 결과 재현을 위한 랜덤 시드\n",
        "    n_jobs=-1,  # 병렬처리\n",
        "    verbose=2  # 진행 상황 출력\n",
        ")\n",
        "\n",
        "# 모델 훈련 및 하이퍼파라미터 튜닝\n",
        "random_search.fit(X_sample, y_sample)\n",
        "\n",
        "# 최적의 모델 및 하이퍼파라미터 확인\n",
        "best_model = random_search.best_estimator_\n",
        "best_params = random_search.best_params_\n",
        "print(\"Best KernelRidge model:\", best_model)\n",
        "print(\"Best parameters:\", best_params)\n",
        "\n",
        "# 성능 평가\n",
        "score=val_score(best_model,valiation_df)\n",
        "print(\"KernelRidge (with tuned hyperparameters):\", score)\n",
        "\n",
        "#KernelRidge (with tuned hyperparameters): 0.8778054862842892\n",
        "# KernelRidge (with tuned hyperparameters): 0.8802992518703242 경향화 후 10000개\n",
        "# KernelRidge (with tuned hyperparameters): 0.875~~~~          경량화 후 20000개 오히려 더 떨어짐;;\n",
        "# 30000개는 터짐"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-UOS2H2lbwO",
        "outputId": "30ef5119-42b7-4a99-d511-3d5492b2c7f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
            "Best KernelRidge model: KernelRidge(alpha=84.89148242660839, coef0=0.4434590423297464, degree=4,\n",
            "            gamma=5.227428293819941, kernel='poly')\n",
            "Best parameters: {'alpha': 84.89148242660839, 'coef0': 0.4434590423297464, 'degree': 4, 'gamma': 5.227428293819941, 'kernel': 'poly'}\n",
            "KernelRidge (with tuned hyperparameters): 0.8802992518703242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = KernelRidge(\n",
        "    alpha=0.06522117123602399,\n",
        "    coef0=0.8154614284548342,\n",
        "    degree=2,\n",
        "    gamma=0.081134195274865,\n",
        "    kernel='linear'\n",
        ")\n",
        "\n",
        "# 모델 학습\n",
        "model.fit(X, y)\n",
        "\n",
        "\n",
        "# 성능 평가\n",
        "score=val_score(model,valiation_df)\n",
        "print(\"KernelRidge (with tuned hyperparameters):\", score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCgb_jzymrDn",
        "outputId": "ab5bc3b9-81ca-4685-8909-8ee80e9b7216"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KernelRidge (with tuned hyperparameters): 0.8778054862842892\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(best_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPIfzLg0nKn9",
        "outputId": "319a8123-45fc-450a-c94a-a3f7ae64f59c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'alpha': 0.3242918568673425, 'coef0': 0.6364104112637804, 'degree': 3, 'gamma': 0.06632755719763837, 'kernel': 'rbf'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Predict on test data\n",
        "X_test = test_df.iloc[:, 1:]\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Identify top 10% of predicted values\n",
        "threshold = np.percentile(y_pred, 90)\n",
        "top_10_percent_mask = y_pred >= threshold\n",
        "\n",
        "# Create submission file\n",
        "submission_df = pd.read_csv('/content/drive/MyDrive/dacon/2024_8_data/submission/sample_submission.csv')\n",
        "submission_df['y'] = y_pred\n",
        "submission_df.to_csv('/content/drive/MyDrive/dacon/2024_8_data/submission/Reduce3_KernelRidge_submission.csv', index=False)"
      ],
      "metadata": {
        "id": "wEP8X6_L7e4B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}